{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "094dd6c2-9921-404e-a4b6-6fe99030dadb",
   "metadata": {},
   "source": [
    "# Computing Discrepancies in Kinetic Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ff4402-a8a6-4e6d-8e2f-27cf07609278",
   "metadata": {},
   "source": [
    "created 2025-08-08, by Kananovich. The code is based on the code an_benchmark, version 22.\n",
    "2025-10-15 updated\n",
    "\n",
    "2025-10-16 updated to calculate frational uncertainty as per textbook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75004d4-9d9f-4fd3-b360-ab59c22c0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Computing Discrepancies in Kinetic Temperature\n",
    "\n",
    "# created 2025-08-08, by Kananovich. The code is based on the code an_benchmark, version 22.\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "from scipy import constants as cnst\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# ### top-level data used very below:\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,2.0E-6)\n",
    "#arr_framerate = np.arange(30.0, 305.0, 30.0)\n",
    "#arr_discrep_average = np.zeros((len(arr_resol), len(arr_framerate)))\n",
    "#number_of_averaging_iterations = 2\n",
    "#levels_f_contour = np.array([0,10,40,80,160,320,1000,3000,4000,6000])\n",
    "#max_lev = np.max(levels_f_contour)\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,0.4E-7) #values to run at HPC\n",
    "#arr_framerate = np.arange(30.0, 506.0, 2.0) #values to run at HPC\n",
    "#number_of_averaging_iterations = 100 #values to run at HPC\n",
    "\n",
    "arr_resol = np.arange(1E-6,40E-6,1.0E-7) #values to run at HPC FAST\n",
    "arr_framerate = np.arange(30.0, 506.0, 10.0) #values to run at HPC FAST\n",
    "number_of_averaging_iterations = 20 #values to run at HPC FAST\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,2.0E-6) #values for debug\n",
    "#arr_framerate = np.arange(30.0, 506.0, 60) #values for debug\n",
    "#number_of_averaging_iterations = 3  #values for debug\n",
    "\n",
    "arr_discrep_average = np.zeros((len(arr_resol), len(arr_framerate)))\n",
    "arr_discrep_sum_of_squares = np.zeros((len(arr_resol), len(arr_framerate))) # array to hold sum of squared discrepancies\n",
    "\n",
    "#levels_f_contour = np.array([0,10,40,80,160,320,1000,5000,10000,20000])\n",
    "levels_f_contour = np.array([0,1,5,6,7,10,100,500,1000])\n",
    "max_lev = np.max(levels_f_contour)\n",
    "\n",
    "\n",
    "# general parameters.\n",
    "# camera resolution updated on 2025-04-17 using the data provided by Parth\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "nP = 1000 #number of particles\n",
    "rho = 1510.0\n",
    "dust_diam = 7.14E-6\n",
    "fps = 1.0E10 # camera framerate in frames per second\n",
    "#fps = 295.0 # camera framerate in frames per second\n",
    "time_step = 1.0 / fps\n",
    "#res_meters_per_px = 30.0E-20\n",
    "res_meters_per_px = 30E-6\n",
    "resol_SI = 1.0 / res_meters_per_px # camera resolution in px/meters\n",
    "dust_mass = 4.0 / 3.0 * np.pi * (dust_diam / 2.0)**3 * rho #mass of the dust particles\n",
    "kin_Tx = 1000.0 #kinetic temperature (in Kelvins) along the x axis\n",
    "kin_Ty = 1000.0 #kinetic temperature (in Kelvins) along the y axis\n",
    "drift_x = 0  # asuming the average x-component of the particles is zero (no drift)\n",
    "left_x_bord = 0\n",
    "right_x_bord = 1751.0 # right border of the field of view in pixels\n",
    "left_x_bord_SI = left_x_bord / resol_SI\n",
    "right_x_bord_SI = right_x_bord / resol_SI #coordinated of the right border\n",
    "    #of the filed of view in meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf36570-6b0d-40d7-aaa6-a62a2003e0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05252999999999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_x_bord_SI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d518245-4172-4692-af32-75db9435b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.877863591930901e-13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacbf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k in range from 0 to\n",
      "20\n",
      "..........\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Computing Discrepancies in Kinetic Temperature\n",
    "\n",
    "# created 2025-08-08, by Kananovich. The code is based on the code an_benchmark, version 22.\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "from scipy import constants as cnst\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# ### top-level data used very below:\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,2.0E-6)\n",
    "#arr_framerate = np.arange(30.0, 305.0, 30.0)\n",
    "#arr_discrep_average = np.zeros((len(arr_resol), len(arr_framerate)))\n",
    "#number_of_averaging_iterations = 2\n",
    "#levels_f_contour = np.array([0,10,40,80,160,320,1000,3000,4000,6000])\n",
    "#max_lev = np.max(levels_f_contour)\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,0.4E-7) #values to run at HPC\n",
    "#arr_framerate = np.arange(30.0, 506.0, 2.0) #values to run at HPC\n",
    "#number_of_averaging_iterations = 100 #values to run at HPC\n",
    "\n",
    "arr_resol = np.arange(1E-6,40E-6,1.0E-7) #values to run at HPC FAST\n",
    "arr_framerate = np.arange(30.0, 506.0, 10.0) #values to run at HPC FAST\n",
    "number_of_averaging_iterations = 20 #values to run at HPC FAST\n",
    "\n",
    "#arr_resol = np.arange(1E-6,40E-6,2.0E-6) #values for debug\n",
    "#arr_framerate = np.arange(30.0, 506.0, 60) #values for debug\n",
    "#number_of_averaging_iterations = 3  #values for debug\n",
    "\n",
    "arr_discrep_average = np.zeros((len(arr_resol), len(arr_framerate)))\n",
    "arr_discrep_sum_of_squares = np.zeros((len(arr_resol), len(arr_framerate))) # array to hold sum of squared discrepancies\n",
    "\n",
    "#levels_f_contour = np.array([0,10,40,80,160,320,1000,5000,10000,20000])\n",
    "levels_f_contour = np.array([0,1,5,6,7,10,100,500,1000])\n",
    "max_lev = np.max(levels_f_contour)\n",
    "\n",
    "\n",
    "# general parameters.\n",
    "# camera resolution updated on 2025-04-17 using the data provided by Parth\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "nP = 1000 #number of particles\n",
    "rho = 1510.0\n",
    "dust_diam = 7.14E-6\n",
    "fps = 1.0E10 # camera framerate in frames per second\n",
    "#fps = 295.0 # camera framerate in frames per second\n",
    "time_step = 1.0 / fps\n",
    "res_meters_per_px = 30.0E-20\n",
    "#res_meters_per_px = 30E-6\n",
    "resol_SI = 1.0 / res_meters_per_px # camera resolution in px/meters\n",
    "dust_mass = 4.0 / 3.0 * np.pi * (dust_diam / 2.0)**3 * rho #mass of the dust particles\n",
    "kin_Tx = 1000.0 #kinetic temperature (in Kelvins) along the x axis\n",
    "kin_Ty = 1000.0 #kinetic temperature (in Kelvins) along the y axis\n",
    "drift_x = 0  # asuming the average x-component of the particles is zero (no drift)\n",
    "left_x_bord = 0\n",
    "right_x_bord = 1751.0 # right border of the field of view in pixels\n",
    "left_x_bord_SI = left_x_bord / resol_SI\n",
    "right_x_bord_SI = right_x_bord / resol_SI #coordinated of the right border\n",
    "    #of the filed of view in meters\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "resol_SI\n",
    "\n",
    "\n",
    "# ## Step 1. Creating an array of artificial velocities\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "arr_ind = np.arange(0,nP,1,dtype = 'int') # array of particles ID numbers\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "sigma_x = np.sqrt(cnst.k * kin_Tx / dust_mass)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "sigma_x\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "art_vx_rv = sts.norm(drift_x,sigma_x)\n",
    "arr_sample_vx = art_vx_rv.rvs(nP)\n",
    "\n",
    "\n",
    "# ## Step 2. Creating an array of artificial coordinates\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "art_x_prev_rv = sts.uniform(left_x_bord_SI, right_x_bord_SI - left_x_bord_SI)\n",
    "arr_sample_prev_x = art_x_prev_rv.rvs(nP)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "arr_prev_x_inResolChunks = arr_sample_prev_x * resol_SI\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "arr_prev_x_inResolChunks_int = arr_prev_x_inResolChunks.astype(int)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "arr_rough_prev_x = arr_prev_x_inResolChunks_int.astype('float64') / resol_SI\n",
    "\n",
    "\n",
    "# ## Step 3. Creating an array of artificial coordinates for the \"next frame\"\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "arr_next_x = arr_rough_prev_x + arr_sample_vx * time_step\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "arr_next_x_inResolChunks = arr_next_x * resol_SI\n",
    "arr_next_x_inResolChunks_int = arr_next_x_inResolChunks.astype('int64')\n",
    "arr_rough_next_x = arr_next_x_inResolChunks_int.astype('float64') / resol_SI\n",
    "\n",
    "\n",
    "# ## Step 4. Calculating the restored velocities\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "arr_vx_restored = (arr_rough_next_x - arr_rough_prev_x) / time_step\n",
    "\n",
    "\n",
    "# ## Step 5. Calculating the array of discrepancies\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "arr_discrep_x = np.abs(arr_vx_restored - arr_sample_vx)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "arr_frac_discrep_x = np.abs(arr_discrep_x / arr_sample_vx) * 100\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "arr_frac_discrep_x.min()\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "arr_frac_discrep_x.max()\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "arr_frac_discrep_x.mean()\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "def create_art_vels(tTx, tTy, N_particles, metersPerPx, frps, ro, diam, drift_x, drift_y, left_x, right_x, lefty, right_y):\n",
    "    import numpy as np\n",
    "    import scipy.stats as sts\n",
    "    from scipy import constants as cnst\n",
    "    resol_SI = 1.0 / metersPerPx # camera resolution in px/meters\n",
    "   \n",
    "    dust_mass = 4.0 / 3.0 * np.pi * (diam / 2.0)**3 * ro #mass of the dust particles\n",
    "    sigma_x = np.sqrt(cnst.k * tTx / dust_mass)\n",
    "    sigma_y = np.sqrt(cnst.k * tTy / dust_mass)\n",
    "    left_x_bord_SI = left_x / resol_SI\n",
    "    right_x_bord_SI = right_x / resol_SI #coordinated of the right border\n",
    "    time_step = 1.0 / frps\n",
    "\n",
    "\n",
    "    #Creating the arrays to store data in:\n",
    "    arr_ind = np.arange(0,N_particles,1,dtype = 'int') # array of particles ID numbers\n",
    "    arr_first_frame_no = np.zeros(N_particles, dtype = 'int')\n",
    "    arr_first_frame_no = arr_first_frame_no + int(1)        #array to store the frist frame number\n",
    "    arr_next_frame_no = np.zeros(N_particles, dtype = 'int')\n",
    "    arr_next_frame_no = arr_next_frame_no + int(2)        #array to store the frist frame number\n",
    "\n",
    "    #array to store the \"nonexistent\" data:\n",
    "\n",
    "    arr_nan = np.empty(N_particles)\n",
    "    arr_nan.fill(np.nan)\n",
    "    \n",
    "    \n",
    "\n",
    "    artif_vx_rv = sts.norm(drift_x,sigma_x)\n",
    "    arr_sample_vx = artif_vx_rv.rvs(N_particles)\n",
    "\n",
    "    #Array of artificial coordinates for the \"previous\" frame:\n",
    "    art_x_prev_rv = sts.uniform(left_x_bord_SI, right_x_bord_SI - left_x_bord_SI)\n",
    "    arr_sample_prev_x = art_x_prev_rv.rvs(N_particles)\n",
    "\n",
    "    arr_prev_x_inResolChunks = arr_sample_prev_x * resol_SI\n",
    "    arr_prev_x_inResolChunks_int = arr_prev_x_inResolChunks.astype(int)\n",
    "    arr_rough_prev_x = arr_prev_x_inResolChunks_int.astype('float64') / resol_SI\n",
    "    \n",
    "    ## Step 3. Creating an array of artificial coordinates for the \"next frame\"\n",
    "    arr_next_x = arr_rough_prev_x + arr_sample_vx * time_step\n",
    "    arr_next_x_inResolChunks = arr_next_x * resol_SI\n",
    "    arr_next_x_inResolChunks_int = arr_next_x_inResolChunks.astype('int64')\n",
    "    arr_rough_next_x = arr_next_x_inResolChunks_int.astype('float64') / resol_SI\n",
    "\n",
    "## Step 4: Calculating the \"restored\" velocities:\n",
    "    arr_vx_restored = (arr_rough_next_x - arr_rough_prev_x) / time_step\n",
    "\n",
    "    #saving all the data in the output dataframe:\n",
    "    \n",
    "    #first, create a dataframe storing the data of the first 'video frame':\n",
    "    \n",
    "    dataFirstFrame = {'particle':arr_ind, 'frame':arr_first_frame_no, 'x': arr_rough_prev_x, 'vx':arr_vx_restored, 'real_vx': arr_sample_vx}\n",
    "    first_df = pd.DataFrame(dataFirstFrame)\n",
    "    \n",
    "    #the same for the next video frame:\n",
    "\n",
    "    dataNextFrame = {'particle':arr_ind, 'frame':arr_next_frame_no, 'x': arr_rough_next_x, 'vx':arr_nan, 'real_vx': arr_nan}\n",
    "    next_df = pd.DataFrame(dataNextFrame)\n",
    "    \n",
    "    ret_df = pd.concat([first_df,next_df], ignore_index = True)\n",
    "    return ret_df\n",
    "df = create_art_vels(1200, 1200, 1000, 1.0E-8, 100, 1510, 7.14E-6, 0, 0, 0, 1751, 0, 400)\n",
    "df\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "df_first = df[df['frame'] == 1]\n",
    "arr_vxTheor = np.array(df_first['real_vx'])\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "counts_xt, bins_xt = np.histogram(arr_vxTheor, bins = 19)\n",
    "fig_x, ax_x = plt.subplots()\n",
    "arr_bins_centers = 0.5 * (bins_xt[1:] + bins_xt[:-1])\n",
    "ax_x.bar(arr_bins_centers, counts_xt, width = (arr_bins_centers[1] - arr_bins_centers[0]))\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "bins_x = arr_bins_centers - 0.5 * (arr_bins_centers[1] - arr_bins_centers[0])\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "bins_x = np.append(bins_x, bins_x[-1] + (bins_x[1] - bins_x[0]))\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "arr_vx = np.array(df_first['vx'])\n",
    "counts_xe, bins_xe = np.histogram(arr_vx, bins = bins_x)\n",
    "#counts_xe, bins_xe = np.histogram(arr_vx, bins = 100)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "bins_xe\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "bins_xt\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "arr_bins_e_centers = 0.5 * (bins_xe[1:] + bins_xe[:-1])\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "ax_x.bar(arr_bins_e_centers, counts_xe, width = (arr_bins_centers[1] - arr_bins_centers[0]), color = 'red')\n",
    "fig_x\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "fig_x_e, ax_x_e = plt.subplots()\n",
    "ax_x_e.bar(arr_bins_e_centers, counts_xe, width = (arr_bins_centers[1] - arr_bins_centers[0]), color = 'red')\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "std = np.std(arr_vx)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "std\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "tT = std**2 * dust_mass / cnst.k\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "tT\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "print(\"k in range from 0 to\")\n",
    "print(number_of_averaging_iterations)\n",
    "print(r\"..........\")\n",
    "for k in range(0, number_of_averaging_iterations):\n",
    "    print(k)    \n",
    "    arr_discrepSq = np.zeros((len(arr_resol), len(arr_framerate)))\n",
    "    for j in range(0, len(arr_framerate)):\n",
    "        frmrt_j = arr_framerate[j]\n",
    "        for i in range(0, len(arr_resol)):\n",
    "            res_i = arr_resol[i]\n",
    "            df_i = create_art_vels(kin_Tx, kin_Ty, 1000, res_i, frmrt_j, 1510, 7.14E-6, 0, 0, 0, 1751, 0, 400)\n",
    "            df_i_ff = df_i[df_i['frame'] == 1]\n",
    "            std_i = np.std(df_i['vx'])\n",
    "            tT = std_i**2 * dust_mass / cnst.k\n",
    "            arr_discrepSq[i, j] = (kin_Tx - std_i**2 * dust_mass / cnst.k)**2\n",
    "    arr_discrep_sum_of_squares = arr_discrep_sum_of_squares + arr_discrepSq\n",
    "    \n",
    "\n",
    "\n",
    "arr_STD = np.sqrt(arr_discrep_sum_of_squares / (number_of_averaging_iterations))\n",
    "arr_SDOM = arr_STD / np.sqrt(number_of_averaging_iterations) # uncertainty as SDOM\n",
    "arr_fracUncert = arr_SDOM / kin_Tx #calculating fractional uncertainty\n",
    "    \n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(arr_framerate, arr_resol * 1000000)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "fig4, ax4 = plt.subplots()\n",
    "khuj = ax4.contour(X, Y, arr_fracUncert)\n",
    "ax4.set_ylabel(r\"resolution ($\\mu$m/px)\")\n",
    "ax4.set_xlabel(r\"framerate (fps)\")\n",
    "ax4.clabel(khuj,\n",
    "          inline=True,       # draw labels on the contour lines\n",
    "          fmt='%1.0f',       # format string for the level numbers\n",
    "          fontsize=8)\n",
    "ax4.grid(True)\n",
    "ax4.set_ylim(9, 30)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from matplotlib import colors\n",
    "# Assuming X, Y, arr_discrep_average are already defined\n",
    "fig4, ax4 = plt.subplots()\n",
    "\n",
    "# Filled contours\n",
    "khuj = ax4.contourf(X, Y, arr_fracUncert, levels= levels_f_contour, norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "# Add colorbar with customized ticks\n",
    "cbar = plt.colorbar(khuj, ax=ax4, label='Discrepancy (%)')\n",
    "\n",
    "# Axis labels\n",
    "ax4.set_ylabel(r\"Resolution ($\\mu$m/px)\")\n",
    "ax4.set_xlabel(r\"Frame Rate (fps)\")\n",
    "\n",
    "# Experimental points\n",
    "ax4.scatter([99, 294], [24.39, 30.69], marker='x', color='red', label='Experimental points', s=100)\n",
    "\n",
    "# Set colorbar limits to enforce end at 400\n",
    "#cbar.ax.set_ylim(0, 400)\n",
    "\n",
    "line_contours = ax4.contour(X, Y, arr_fracUncert, levels=khuj.levels, linewidths=0.5,norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "ax4.clabel(\n",
    "    line_contours,\n",
    "    # khuj,\n",
    "    fmt='%1.0f',\n",
    "    fontsize=12,\n",
    "    colors='white',\n",
    "    inline=True,\n",
    "    inline_spacing=2,\n",
    ")\n",
    "#plt.savefig(f'Discrepancy_{TeV}eV.png', bbox_inches='tight')\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "khuj.levels\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "fig4.savefig(\"contour_fac_uncert.png\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "fig4.savefig(\"contour_frac_uncert.eps\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "        arr_discrep_average,\n",
    "        index=pd.Index(arr_resol, name=\"resolution\"),\n",
    "        columns=pd.Index(arr_framerate, name=\"frame_rate\"))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "df.to_csv(\"ptv_results.csv\", float_format=\"%.9e\")\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"ptv_results.csv\", index_col=0)\n",
    "frame_rates = df.columns.astype(float).to_numpy()\n",
    "resolutions = df.index.to_numpy()\n",
    "Z = df.to_numpy()\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "Xf, Yf = np.meshgrid(frame_rates, resolutions * 1000000)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# Assuming X, Y, arr_discrep_average are already defined\n",
    "fig5, ax5 = plt.subplots()\n",
    "\n",
    "# Filled contours\n",
    "khuj5 = ax5.contourf(Xf, Yf, Z, levels= levels_f_contour, norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "# Add colorbar with customized ticks\n",
    "cbar5 = plt.colorbar(khuj5, ax=ax5, label='Discrepancy (%)')\n",
    "\n",
    "# Axis labels\n",
    "ax5.set_ylabel(r\"Resolution ($\\mu$m/px)\")\n",
    "ax5.set_xlabel(r\"Frame Rate (fps)\")\n",
    "\n",
    "# Experimental points\n",
    "ax5.scatter([25, 99, 294, 25], [24.39, 24.39, 30.69, 30.69], marker='x', color='red', label='Experimental points', s=100)\n",
    "\n",
    "# Set colorbar limits to enforce end at 400\n",
    "#cbar.ax.set_ylim(0, 400)\n",
    "\n",
    "line_contours5 = ax5.contour(Xf, Yf, Z, levels=khuj.levels, linewidths=0.5,norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "ax5.clabel(\n",
    "    line_contours5,\n",
    "    # khuj,\n",
    "    fmt='%1.0f',\n",
    "    fontsize=12,\n",
    "    colors='white',\n",
    "    inline=True,\n",
    "    inline_spacing=2,\n",
    ")\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "fig4\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "fig5.savefig(\"contour_discrepancy_restored.png\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "fig4.savefig(\"contour_discrepancy_restored.eps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da8f05-c857-4d8c-a922-91c3c860966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "        arr_fracUncert,\n",
    "        index=pd.Index(arr_resol, name=\"resolution\"),\n",
    "        columns=pd.Index(arr_framerate, name=\"frame_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8beb243-e06a-431f-863a-f4559337f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ptv_results.csv\", float_format=\"%.9e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3563e9d-fe97-40cd-acbd-a202eb7a8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ptv_results.csv\", index_col=0)\n",
    "frame_rates = df.columns.astype(float).to_numpy()\n",
    "resolutions = df.index.to_numpy()\n",
    "Z = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf0e653-0ada-4826-a9d4-e6e7285afa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf, Yf = np.meshgrid(frame_rates, resolutions * 1000000)\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "# Assuming X, Y, arr_discrep_average are already defined\n",
    "fig5, ax5 = plt.subplots()\n",
    "\n",
    "# Filled contours\n",
    "khuj5 = ax5.contourf(Xf, Yf, Z, levels= levels_f_contour, norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "# Add colorbar with customized ticks\n",
    "cbar5 = plt.colorbar(khuj5, ax=ax5, label='Discrepancy (%)')\n",
    "\n",
    "# Axis labels\n",
    "ax5.set_ylabel(r\"Resolution ($\\mu$m/px)\")\n",
    "ax5.set_xlabel(r\"Frame Rate (fps)\")\n",
    "\n",
    "# Experimental points\n",
    "ax5.scatter([99, 294], [24.39, 30.69], marker='x', color='red', label='Experimental points', s=100)\n",
    "\n",
    "# Set colorbar limits to enforce end at 400\n",
    "#cbar.ax.set_ylim(0, 400)\n",
    "\n",
    "line_contours5 = ax5.contour(Xf, Yf, Z, levels=khuj.levels, linewidths=0.5,norm=colors.Normalize(vmin=0, vmax=max_lev))\n",
    "\n",
    "ax5.clabel(\n",
    "    line_contours5,\n",
    "    # khuj,\n",
    "    fmt='%1.0f',\n",
    "    fontsize=12,\n",
    "    colors='white',\n",
    "    inline=True,\n",
    "    inline_spacing=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a45ba-d9d3-4477-9bcd-1a0d8ab2cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023f95a-873f-4e5a-86fe-fa790c6c8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5.savefig(\"contour_frac_uncert_restored.png\")\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "fig4.savefig(\"contour_frac_uncert_restored.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c0084-a525-42cb-962f-bd0b0e0745d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78af88-0980-4e3e-a37d-8044c79cfb36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
